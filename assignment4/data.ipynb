{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 4,\n",
    "   \"id\": \"208b3c4e\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"\\n\",\n",
    "    \"from sklearn.feature_extraction.text import TfidfVectorizer\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"eefe1553\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Finding a good number of max features\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 5,\n",
    "   \"id\": \"b8d2c096\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"14.901161193847656\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 5,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"# GiB = 50_000 * max_features * 8 / 20^30\\n\",\n",
    "    \"40_000 * 50_000 * 8 / 2**30\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 6,\n",
    "   \"id\": \"af29f7d1\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stderr\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"/home/xavier/miniconda3/envs/pytorch2/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\\n\",\n",
    "      \"  warnings.warn(\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"<Compressed Sparse Row sparse matrix of dtype 'float64'\\n\",\n",
    "       \"\\twith 6999905 stored elements and shape (50000, 104203)>\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 6,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"df = pd.read_csv('./movie_data.csv')\\n\",\n",
    "    \"\\n\",\n",
    "    \"vectorizer = TfidfVectorizer(\\n\",\n",
    "    \"    tokenizer=lambda text: text.split())\\n\",\n",
    "    \"features = vectorizer.fit_transform(df['review'])\\n\",\n",
    "    \"features\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 7,\n",
    "   \"id\": \"84b0368a\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stderr\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"/home/xavier/miniconda3/envs/pytorch2/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\\n\",\n",
    "      \"  warnings.warn(\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"<Compressed Sparse Row sparse matrix of dtype 'float64'\\n\",\n",
    "       \"\\twith 6448704 stored elements and shape (50000, 10000)>\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 7,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"df = pd.read_csv('./movie_data.csv')\\n\",\n",
    "    \"\\n\",\n",
    "    \"vectorizer = TfidfVectorizer(\\n\",\n",
    "    \"    tokenizer=lambda text: text.split(), max_features=10_000)\\n\",\n",
    "    \"features = vectorizer.fit_transform(df['review'])\\n\",\n",
    "    \"features\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 8,\n",
    "   \"id\": \"e979c4cd\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stderr\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"/home/xavier/miniconda3/envs/pytorch2/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\\n\",\n",
    "      \"  warnings.warn(\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"<Compressed Sparse Row sparse matrix of dtype 'float64'\\n\",\n",
    "       \"\\twith 6740949 stored elements and shape (50000, 20000)>\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 8,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"df = pd.read_csv('./movie_data.csv')\\n\",\n",
    "    \"\\n\",\n",
    "    \"vectorizer = TfidfVectorizer(\\n\",\n",
    "    \"    tokenizer=lambda text: text.split(), max_features=20_000)\\n\",\n",
    "    \"features = vectorizer.fit_transform(df['review'])\\n\",\n",
    "    \"features\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 9,\n",
    "   \"id\": \"837a4f48\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stderr\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"/home/xavier/miniconda3/envs/pytorch2/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\\n\",\n",
    "      \"  warnings.warn(\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"<Compressed Sparse Row sparse matrix of dtype 'float64'\\n\",\n",
    "       \"\\twith 6806309 stored elements and shape (50000, 25000)>\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 9,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"df = pd.read_csv('./movie_data.csv')\\n\",\n",
    "    \"\\n\",\n",
    "    \"vectorizer = TfidfVectorizer(\\n\",\n",
    "    \"    tokenizer=lambda text: text.split(), max_features=25_000)\\n\",\n",
    "    \"features = vectorizer.fit_transform(df['review'])\\n\",\n",
    "    \"features\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 10,\n",
    "   \"id\": \"10542b0c\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stderr\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"/home/xavier/miniconda3/envs/pytorch2/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\\n\",\n",
    "      \"  warnings.warn(\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"<Compressed Sparse Row sparse matrix of dtype 'float64'\\n\",\n",
    "       \"\\twith 6850206 stored elements and shape (50000, 30000)>\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 10,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"df = pd.read_csv('./movie_data.csv')\\n\",\n",
    "    \"\\n\",\n",
    "    \"vectorizer = TfidfVectorizer(\\n\",\n",
    "    \"    tokenizer=lambda text: text.split(), max_features=30_000)\\n\",\n",
    "    \"features = vectorizer.fit_transform(df['review'])\\n\",\n",
    "    \"features\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 11,\n",
    "   \"id\": \"73b652cd\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stderr\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"/home/xavier/miniconda3/envs/pytorch2/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\\n\",\n",
    "      \"  warnings.warn(\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"<Compressed Sparse Row sparse matrix of dtype 'float64'\\n\",\n",
    "       \"\\twith 6934144 stored elements and shape (50000, 50000)>\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 11,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"df = pd.read_csv('./movie_data.csv')\\n\",\n",
    "    \"\\n\",\n",
    "    \"vectorizer = TfidfVectorizer(\\n\",\n",
    "    \"    tokenizer=lambda text: text.split(), max_features=50_000)\\n\",\n",
    "    \"features = vectorizer.fit_transform(df['review'])\\n\",\n",
    "    \"features\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 12,\n",
    "   \"id\": \"13505622\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"tensor([[-0.3954, -0.8306, -1.0728,  0.3095],\\n\",\n",
    "      \"        [ 0.9910, -0.2090, -0.0897, -0.3555],\\n\",\n",
    "      \"        [ 0.6591, -1.5207, -1.8367,  0.7066],\\n\",\n",
    "      \"        [-0.4848, -0.9899, -1.0950,  1.0473]])\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"tensor([0.3095, 0.9910, 0.7066, 1.0473])\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 12,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"import torch\\n\",\n",
    "    \"\\n\",\n",
    "    \"tensor = torch.randn(size=(4, 4))\\n\",\n",
    "    \"print(tensor)\\n\",\n",
    "    \"values, indices = torch.max(tensor, dim=1)\\n\",\n",
    "    \"values\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"pytorch2\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.13.2\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ],
   "id": "75f4b07f54d6f4f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
